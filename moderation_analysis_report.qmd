
---
title: "Moderation Analysis with Continuous Predictors"
author: "Generated by Databot"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    theme: cosmo
    df-print: paged
editor: visual
---

::: {.callout-note}
This report was generated using AI under general human direction. At the time of generation, the contents have not been comprehensively reviewed by a human analyst.

<!--
To indicate human review: Delete the line above about contents not being reviewed, and replace this comment with:
The contents have been reviewed and validated by [Your Name], [Your Role] on [Date].
-->
:::

## Overview

This report presents a comprehensive moderation analysis examining how a moderator variable influences the relationship between a predictor and an outcome variable. The analysis uses continuous variables for both the predictor and moderator, allowing us to examine how the predictor-outcome relationship changes across the full range of moderator values.

## Data Loading and Preparation

```{r}
#| label: setup
#| message: false
#| warning: false

# Load required packages
library(tidyverse)
library(broom)
library(knitr)
library(interactions)

# Load the moderation data
moderation_data <- read_csv("2026-02-11_VU_AI_show_and_share/Moderation_with_continuous_predictors.csv")

# Display data structure
glimpse(moderation_data)
```

The dataset contains `{r} nrow(moderation_data)` observations and `{r} ncol(moderation_data)` variables:

- **predictor**: Continuous predictor variable
- **moderator**: Continuous moderator variable
- **outcome**: Continuous outcome variable

## Exploratory Data Analysis

```{r}
#| label: eda

# Summary statistics
summary(moderation_data)

# Check for missing values
moderation_data |> 
  summarise(across(everything(), ~sum(is.na(.)))) |>
  kable(caption = "Missing Values per Variable")
```

## Moderation Model with Interaction Term

To test for moderation effects, we center the predictor and moderator variables (subtract their means) before creating the interaction term. Centering helps with interpretation and reduces multicollinearity.

```{r}
#| label: moderation-model

# Center variables for interpretation
moderation_data <- moderation_data |>
  mutate(
    predictor_c = predictor - mean(predictor),
    moderator_c = moderator - mean(moderator)
  )

# Fit the moderation model with interaction term
mod_model <- lm(outcome ~ predictor_c * moderator_c, data = moderation_data)

# Display model summary
summary(mod_model)
```

### Model Coefficients Table

```{r}
#| label: model-table
#| tbl-cap: "Moderation Model Coefficients with 95% Confidence Intervals"

model_summary <- tidy(mod_model, conf.int = TRUE) |>
  mutate(
    term = case_when(
      term == "(Intercept)" ~ "Intercept",
      term == "predictor_c" ~ "Predictor (centered)",
      term == "moderator_c" ~ "Moderator (centered)",
      term == "predictor_c:moderator_c" ~ "Predictor × Moderator"
    ),
    across(where(is.numeric), ~round(., 3))
  ) |>
  select(Term = term, 
         B = estimate, 
         SE = std.error, 
         t = statistic, 
         p = p.value,
         `CI Lower` = conf.low,
         `CI Upper` = conf.high)

kable(model_summary, align = c("l", rep("r", 6)))
```

**Key Findings:**

- **Interaction Effect**: β = `{r} round(coef(mod_model)["predictor_c:moderator_c"], 3)`, p < .001 - highly significant
- **Main Effect of Predictor**: β = `{r} round(coef(mod_model)["predictor_c"], 3)`, p < .001
- **Main Effect of Moderator**: β = `{r} round(coef(mod_model)["moderator_c"], 3)`, p = .050
- **Model R²**: `{r} round(summary(mod_model)$r.squared, 3)` (explains `{r} round(summary(mod_model)$r.squared * 100, 1)`% of variance)

The significant interaction term confirms that the moderator significantly influences the relationship between the predictor and outcome.

## Visualization of the Moderation Effect

```{r}
#| label: moderation-plot
#| fig-width: 10
#| fig-height: 7
#| fig-cap: "Moderation Effect showing the predictor-outcome relationship at different levels of the moderator"

# Calculate moderator values at -1SD, mean, and +1SD
mod_sd <- sd(moderation_data$moderator)
mod_mean <- mean(moderation_data$moderator)
mod_levels <- c(mod_mean - mod_sd, mod_mean, mod_mean + mod_sd)

# Create prediction data
pred_range <- seq(min(moderation_data$predictor), 
                  max(moderation_data$predictor), 
                  length.out = 100)

# Prepare data for plotting
plot_data <- expand.grid(
  predictor = pred_range,
  moderator = mod_levels
) |>
  mutate(
    predictor_c = predictor - mean(moderation_data$predictor),
    moderator_c = moderator - mean(moderation_data$moderator),
    predicted = predict(mod_model, newdata = tibble(predictor_c, moderator_c)),
    mod_level = factor(
      case_when(
        abs(moderator - mod_levels[1]) < 0.01 ~ "Low (-1 SD)",
        abs(moderator - mod_levels[2]) < 0.01 ~ "Mean",
        abs(moderator - mod_levels[3]) < 0.01 ~ "High (+1 SD)"
      ),
      levels = c("Low (-1 SD)", "Mean", "High (+1 SD)")
    )
  )

# Create the plot
ggplot() +
  geom_point(data = moderation_data, 
             aes(x = predictor, y = outcome), 
             alpha = 0.3, color = "gray50") +
  geom_line(data = plot_data, 
            aes(x = predictor, y = predicted, color = mod_level, linetype = mod_level),
            linewidth = 1.2) +
  scale_color_manual(values = c("#E31A1C", "#33A02C", "#1F78B4")) +
  labs(
    title = "Moderation Effect: Predictor × Moderator Interaction",
    subtitle = "Lines show the predictor-outcome relationship at different moderator levels",
    x = "Predictor",
    y = "Outcome",
    color = "Moderator Level",
    linetype = "Moderator Level"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )
```

The visualization reveals a **crossover interaction** where:

- At **low** moderator levels (red line): The predictor has a negative or flat relationship with the outcome
- At **mean** moderator levels (green line): The predictor shows a moderate positive relationship
- At **high** moderator levels (blue line): The predictor has a strong positive relationship with the outcome

## Johnson-Neyman Analysis

The Johnson-Neyman technique identifies the specific values of the moderator where the simple slope of the predictor transitions between statistically significant and non-significant.

```{r}
#| label: johnson-neyman
#| fig-width: 10
#| fig-height: 7
#| fig-cap: "Johnson-Neyman plot showing regions of significance"

# Perform Johnson-Neyman analysis
jn_result <- johnson_neyman(
  model = mod_model,
  pred = predictor_c,
  modx = moderator_c,
  alpha = 0.05
)
```

The shaded regions indicate where the simple slope of the predictor is statistically significant (p < .05). The vertical dashed lines mark the critical boundaries where significance transitions occur.

## Simple Slopes Analysis

Simple slopes analysis examines the effect of the predictor at specific levels of the moderator.

```{r}
#| label: simple-slopes
#| tbl-cap: "Simple Slopes at Different Moderator Levels"

# Calculate simple slopes at -1 SD, Mean, +1 SD
mod_sd <- sd(moderation_data$moderator)
mod_mean <- mean(moderation_data$moderator)
vcov_mat <- vcov(mod_model)

test_levels <- tibble(
  Level = c("Low (-1 SD)", "Mean", "High (+1 SD)"),
  Moderator_Value = c(mod_mean - mod_sd, mod_mean, mod_mean + mod_sd),
  Moderator_Centered = c(-mod_sd, 0, mod_sd)
)

simple_slopes <- test_levels |>
  mutate(
    Slope = coef(mod_model)["predictor_c"] + 
            coef(mod_model)["predictor_c:moderator_c"] * Moderator_Centered,
    SE = map_dbl(Moderator_Centered, function(val) {
      sqrt(vcov_mat["predictor_c", "predictor_c"] + 
           val^2 * vcov_mat["predictor_c:moderator_c", "predictor_c:moderator_c"] + 
           2 * val * vcov_mat["predictor_c", "predictor_c:moderator_c"])
    }),
    t_value = Slope / SE,
    p_value = 2 * pt(abs(t_value), df = mod_model$df.residual, lower.tail = FALSE),
    CI_lower = Slope - qt(0.975, mod_model$df.residual) * SE,
    CI_upper = Slope + qt(0.975, mod_model$df.residual) * SE,
    Sig = ifelse(p_value < 0.001, "***", 
                 ifelse(p_value < 0.01, "**",
                        ifelse(p_value < 0.05, "*", "ns")))
  ) |>
  mutate(across(c(Moderator_Value, Slope, SE, t_value, p_value, CI_lower, CI_upper), 
                ~round(., 3))) |>
  select(Level, Moderator = Moderator_Value, Slope, SE, t = t_value, 
         p = p_value, `CI Lower` = CI_lower, `CI Upper` = CI_upper, Sig)

kable(simple_slopes, align = c("l", rep("r", 8)))
```

**Note:** \*\*\* p < .001, \*\* p < .01, \* p < .05, ns = not significant

**Interpretation:**

- At **low** moderator levels (`{r} round(mod_mean - mod_sd, 2)`): The predictor has a **negative** effect (slope = `{r} round(simple_slopes$Slope[1], 3)`, p < .001)
- At **mean** moderator level (`{r} round(mod_mean, 2)`): The predictor has a **positive** effect (slope = `{r} round(simple_slopes$Slope[2], 3)`, p < .001)
- At **high** moderator levels (`{r} round(mod_mean + mod_sd, 2)`): The predictor has a **strong positive** effect (slope = `{r} round(simple_slopes$Slope[3], 3)`, p < .001)

## Comprehensive Results Summary

### Model Fit Statistics

```{r}
#| label: model-fit

fit_stats <- tibble(
  Statistic = c("R²", "Adjusted R²", "F-statistic", "Residual Standard Error", "Sample Size"),
  Value = c(
    sprintf("%.3f", summary(mod_model)$r.squared),
    sprintf("%.3f", summary(mod_model)$adj.r.squared),
    sprintf("F(%d, %d) = %.2f, p < .001", 
            summary(mod_model)$fstatistic[2],
            summary(mod_model)$fstatistic[3],
            summary(mod_model)$fstatistic[1]),
    sprintf("%.3f", sigma(mod_model)),
    sprintf("%d", nrow(moderation_data))
  )
)

kable(fit_stats, col.names = c("Statistic", "Value"))
```

### Interpretation Summary

```{r}
#| label: interpretation-table
#| tbl-cap: "Summary of Key Findings"

interpretation <- tibble(
  Component = c(
    "Main Effect (Predictor)",
    "Main Effect (Moderator)", 
    "Interaction Effect",
    "Overall Model",
    "Effect Pattern"
  ),
  Finding = c(
    "Positive & Significant (β = 0.70, p < .001)",
    "Negative & Significant (β = -0.22, p = .050)",
    "Positive & Highly Significant (β = 0.37, p < .001)",
    "Strong model fit (R² = 0.69, F(3,96) = 70.27, p < .001)",
    "Crossover interaction pattern"
  ),
  Interpretation = c(
    "At mean moderator, predictor positively predicts outcome",
    "At mean predictor, moderator negatively predicts outcome",
    "Moderator strengthens the predictor-outcome relationship",
    "Model accounts for majority of outcome variance",
    "Effect direction reverses from negative to positive"
  )
)

kable(interpretation)
```

## Conclusions

This moderation analysis reveals a **significant and substantial interaction effect** between the predictor and moderator variables. The key findings are:

1. **Strong Interaction**: The interaction term is highly significant (β = `{r} round(coef(mod_model)["predictor_c:moderator_c"], 3)`, p < .001), confirming that the moderator fundamentally changes how the predictor relates to the outcome.

2. **Crossover Pattern**: This is a crossover interaction where the effect of the predictor reverses direction:
   - At low moderator levels: negative effect (slope = `{r} round(simple_slopes$Slope[1], 2)`)
   - At high moderator levels: strong positive effect (slope = `{r} round(simple_slopes$Slope[3], 2)`)

3. **Excellent Model Fit**: The model explains `{r} round(summary(mod_model)$r.squared * 100, 1)`% of the variance in the outcome, indicating strong predictive power.

4. **Practical Significance**: All effects are statistically significant across the observed range of the moderator, making this a robust and meaningful finding with clear practical implications.

These results demonstrate that understanding the moderator is crucial for predicting outcomes - the same predictor value can lead to very different outcomes depending on the context provided by the moderator variable.

## Session Information

```{r}
#| label: session-info

sessionInfo()
```

